{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb7ace0-d480-4cfc-83ec-9baf4050e275",
   "metadata": {},
   "source": [
    "### Create a DataFrame of subjects with available timeseries data & Check subjects from the QC.json that don't have the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f47bd1e8-bca6-47e6-8bea-d3f4314070e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing subjects: 27\n",
      "Missing Subject: sub-subSEQ1NKISENR45, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR68, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR107, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR116, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR118, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR145, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR149, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR151, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR176, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR45, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR68, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR107, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR116, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR118, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR145, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR149, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR151, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR176, Sample: New_York\n",
      "Missing Subject: sub-CT04, Sample: Cape_Town_UCT/Allegra\n",
      "Missing Subject: sub-ESCO5, Sample: Cape_Town_UCT/Allegra\n",
      "Missing Subject: sub-subSEQ1NKISENR116, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR118, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR145, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR149, Sample: New_York\n",
      "Missing Subject: sub-subSEQ1NKISENR151, Sample: New_York\n",
      "Missing Subject: sub-P00366620181127, Sample: Brazil\n",
      "Missing Subject: sub-MADHC085, Sample: Chiba/CHBSRPB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the QC JSON file\n",
    "qc_file_path = \"/global/homes/p/pakmasha/ENIGMA-OCD results/QC/QC.json\"\n",
    "with open(qc_file_path, \"r\") as f:\n",
    "    qc_data = json.load(f)\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = \"/pscratch/sd/p/pakmasha/ENIGMA_unzip\"\n",
    "\n",
    "# Initialize a list to store missing subjects\n",
    "# subjects_with_timeseries_data = []\n",
    "missing_subjects = []\n",
    "\n",
    "# Traverse through sample folders and subsample folders\n",
    "for qc_entry in qc_data:\n",
    "    site = qc_entry[\"site\"]\n",
    "    failed_subjects = qc_entry[\"failed_subjects\"]\n",
    "    \n",
    "    # Determine if the site has subsamples\n",
    "    site_path = os.path.join(base_dir, site)\n",
    "    if os.path.exists(site_path):\n",
    "        halfpipe_path = os.path.join(site_path, \"halfpipe\")\n",
    "        \n",
    "        if os.path.exists(halfpipe_path):\n",
    "            # Direct sample with a \"halfpipe\" folder\n",
    "            available_subjects = os.listdir(halfpipe_path)\n",
    "            \n",
    "            # Store formatted IDs and sample info\n",
    "            # for subject in available_subjects:\n",
    "            #     subjects_with_timeseries_data.append({\"Sample\": site, \"Formatted ID\": subject})\n",
    "            \n",
    "            for subject in failed_subjects:\n",
    "                if subject not in available_subjects:\n",
    "                    missing_subjects.append({\"Subject\": subject, \"Sample\": site})\n",
    "        else:\n",
    "            # Subsamples exist\n",
    "            for subsample_folder in os.listdir(site_path):\n",
    "                subsample_path = os.path.join(site_path, subsample_folder)\n",
    "                halfpipe_path = os.path.join(subsample_path, \"halfpipe\")\n",
    "                \n",
    "                if os.path.exists(halfpipe_path):\n",
    "                    available_subjects = os.listdir(halfpipe_path)\n",
    "                    \n",
    "                    # Store formatted IDs and sample/subsample info\n",
    "                    # for subject in available_subjects:\n",
    "                    #     subjects_with_timeseries_data.append(\n",
    "                    #         {\"Sample\": f\"{site}/{subsample_folder}\", \"Formatted ID\": subject}\n",
    "                    #     )\n",
    "                    \n",
    "                    for subject in failed_subjects:\n",
    "                        if subject not in available_subjects:\n",
    "                            missing_subjects.append(\n",
    "                                {\"Subject\": subject, \"Sample\": f\"{site}/{subsample_folder}\"}\n",
    "                            )\n",
    "                else:\n",
    "                    # If there's no halfpipe, log the issue\n",
    "                    print(f\"No halfpipe folder found for {site}/{subsample_folder}\")\n",
    "    else:\n",
    "        print(f\"Site folder not found: {site}\")\n",
    "\n",
    "# # Create a DataFrame from subjects_with_timeseries_data\n",
    "# Subjects_with_timeseries_data = pd.DataFrame(subjects_with_timeseries_data)        \n",
    "        \n",
    "# Print results\n",
    "print(f\"\\nNumber of missing subjects: {len(missing_subjects)}\")\n",
    "for entry in missing_subjects:\n",
    "    print(f\"Missing Subject: {entry['Subject']}, Sample: {entry['Sample']}\")\n",
    "    \n",
    "# # Display the Subjects_with_timeseries_data DataFrame\n",
    "# print(\"\\nSubjects with timeseries data:\")\n",
    "# print(Subjects_with_timeseries_data.head())    \n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# Subjects_with_timeseries_data.to_csv(\"/global/homes/p/pakmasha/ENIGMA-OCD results/QC/Subjects_with_timeseries_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf946328-805d-4f79-9822-635d93933bd0",
   "metadata": {},
   "source": [
    "### Check the number of subjects with available data in each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f591458-84cf-4f0e-b1e0-62f5ebf807a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Formatted ID\n",
      "Sample                                       \n",
      "Amsterdam_AMC                              50\n",
      "Amsterdam_VUmc                             83\n",
      "Bangalore_NIMHANS                         470\n",
      "Barcelona_HCPB                            103\n",
      "Barcelone_Bellvitge/ANTIGA_1.5T           196\n",
      "Barcelone_Bellvitge/COMPULSE_3T            37\n",
      "Barcelone_Bellvitge/PROV_1.5T             107\n",
      "Barcelone_Bellvitge/RESP_CBT_3T            75\n",
      "Bergen                                     70\n",
      "Braga_UMinho/Braga_1.5T                    49\n",
      "Braga_UMinho/Braga_1.5T_act               113\n",
      "Braga_UMinho/Braga_3T                      63\n",
      "Brazil                                    115\n",
      "Cape_Town_UCT/Allegra                      11\n",
      "Cape_Town_UCT/Skyra                        46\n",
      "Chiba/CHB                                  46\n",
      "Chiba/CHBC                                 60\n",
      "Chiba/CHBSRPB                              99\n",
      "Dresden                                    56\n",
      "Kyoto_KPU/Kyoto1.5T                        40\n",
      "Kyoto_KPU/Kyoto3T                          79\n",
      "Kyushu                                     43\n",
      "Milan_HSR                                  78\n",
      "NYSPI_Columbia/Adults                      73\n",
      "NYSPI_Columbia/Pediatric                   48\n",
      "New_York                                   76\n",
      "Seoul_SNU                                 108\n",
      "Shanghai_SMCH                              96\n",
      "UCLA                                       69\n",
      "Vancouver_BCCHR                            55\n",
      "Yale_Gruner                                45\n",
      "Yale_Pittinger/HCP_Prisma                  73\n",
      "Yale_Pittinger/HCP_Trio                    55\n",
      "Yale_Pittinger/Yale_2014                   97\n"
     ]
    }
   ],
   "source": [
    "# Count the number of subjects for each sample\n",
    "subject_counts = Subjects_with_timeseries_data.groupby(\"Sample\").nunique()\n",
    "\n",
    "# Display the result\n",
    "print(subject_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96787b-6dda-47e5-8e42-600e3d9b38cb",
   "metadata": {},
   "source": [
    "### Double-check specific folders if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17f848f7-7d14-46ef-901a-4ffd669d118d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the folder '/pscratch/sd/p/pakmasha/ENIGMA_unzip/Dresden/halfpipe': 56\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = \"/pscratch/sd/p/pakmasha/ENIGMA_unzip/Dresden/halfpipe\"\n",
    "\n",
    "# Count the number of files in the folder\n",
    "folder_count = len([f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))])\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of files in the folder '{folder_path}': {folder_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
